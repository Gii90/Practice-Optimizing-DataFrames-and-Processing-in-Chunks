{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Practice Optimizing DataFrames and Processing in Chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.options.display.max_columns = 99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id  member_id  loan_amnt  funded_amnt  funded_amnt_inv        term  \\\n",
      "0  1077501  1296599.0     5000.0       5000.0           4975.0   36 months   \n",
      "1  1077430  1314167.0     2500.0       2500.0           2500.0   60 months   \n",
      "2  1077175  1313524.0     2400.0       2400.0           2400.0   36 months   \n",
      "3  1076863  1277178.0    10000.0      10000.0          10000.0   36 months   \n",
      "4  1075358  1311748.0     3000.0       3000.0           3000.0   60 months   \n",
      "\n",
      "  int_rate  installment grade sub_grade                 emp_title emp_length  \\\n",
      "0   10.65%       162.87     B        B2                       NaN  10+ years   \n",
      "1   15.27%        59.83     C        C4                     Ryder   < 1 year   \n",
      "2   15.96%        84.33     C        C5                       NaN  10+ years   \n",
      "3   13.49%       339.31     C        C1       AIR RESOURCES BOARD  10+ years   \n",
      "4   12.69%        67.79     B        B5  University Medical Group     1 year   \n",
      "\n",
      "  home_ownership  annual_inc verification_status   issue_d  loan_status  \\\n",
      "0           RENT     24000.0            Verified  Dec-2011   Fully Paid   \n",
      "1           RENT     30000.0     Source Verified  Dec-2011  Charged Off   \n",
      "2           RENT     12252.0        Not Verified  Dec-2011   Fully Paid   \n",
      "3           RENT     49200.0     Source Verified  Dec-2011   Fully Paid   \n",
      "4           RENT     80000.0     Source Verified  Dec-2011      Current   \n",
      "\n",
      "  pymnt_plan         purpose                 title zip_code addr_state    dti  \\\n",
      "0          n     credit_card              Computer    860xx         AZ  27.65   \n",
      "1          n             car                  bike    309xx         GA   1.00   \n",
      "2          n  small_business  real estate business    606xx         IL   8.72   \n",
      "3          n           other              personel    917xx         CA  20.00   \n",
      "4          n           other              Personal    972xx         OR  17.94   \n",
      "\n",
      "   delinq_2yrs earliest_cr_line  inq_last_6mths  open_acc  pub_rec  revol_bal  \\\n",
      "0          0.0         Jan-1985             1.0       3.0      0.0    13648.0   \n",
      "1          0.0         Apr-1999             5.0       3.0      0.0     1687.0   \n",
      "2          0.0         Nov-2001             2.0       2.0      0.0     2956.0   \n",
      "3          0.0         Feb-1996             1.0      10.0      0.0     5598.0   \n",
      "4          0.0         Jan-1996             0.0      15.0      0.0    27783.0   \n",
      "\n",
      "  revol_util  total_acc initial_list_status  out_prncp  out_prncp_inv  \\\n",
      "0      83.7%        9.0                   f       0.00           0.00   \n",
      "1       9.4%        4.0                   f       0.00           0.00   \n",
      "2      98.5%       10.0                   f       0.00           0.00   \n",
      "3        21%       37.0                   f       0.00           0.00   \n",
      "4      53.9%       38.0                   f     461.73         461.73   \n",
      "\n",
      "    total_pymnt  total_pymnt_inv  total_rec_prncp  total_rec_int  \\\n",
      "0   5863.155187          5833.84          5000.00         863.16   \n",
      "1   1008.710000          1008.71           456.46         435.17   \n",
      "2   3005.666844          3005.67          2400.00         605.67   \n",
      "3  12231.890000         12231.89         10000.00        2214.92   \n",
      "4   3581.120000          3581.12          2538.27        1042.85   \n",
      "\n",
      "   total_rec_late_fee  recoveries  collection_recovery_fee last_pymnt_d  \\\n",
      "0                0.00        0.00                     0.00     Jan-2015   \n",
      "1                0.00      117.08                     1.11     Apr-2013   \n",
      "2                0.00        0.00                     0.00     Jun-2014   \n",
      "3               16.97        0.00                     0.00     Jan-2015   \n",
      "4                0.00        0.00                     0.00     Jun-2016   \n",
      "\n",
      "   last_pymnt_amnt last_credit_pull_d  collections_12_mths_ex_med  \\\n",
      "0           171.62           Jun-2016                         0.0   \n",
      "1           119.66           Sep-2013                         0.0   \n",
      "2           649.91           Jun-2016                         0.0   \n",
      "3           357.48           Apr-2016                         0.0   \n",
      "4            67.79           Jun-2016                         0.0   \n",
      "\n",
      "   policy_code application_type  acc_now_delinq  chargeoff_within_12_mths  \\\n",
      "0          1.0       INDIVIDUAL             0.0                       0.0   \n",
      "1          1.0       INDIVIDUAL             0.0                       0.0   \n",
      "2          1.0       INDIVIDUAL             0.0                       0.0   \n",
      "3          1.0       INDIVIDUAL             0.0                       0.0   \n",
      "4          1.0       INDIVIDUAL             0.0                       0.0   \n",
      "\n",
      "   delinq_amnt  pub_rec_bankruptcies  tax_liens  \n",
      "0          0.0                   0.0        0.0  \n",
      "1          0.0                   0.0        0.0  \n",
      "2          0.0                   0.0        0.0  \n",
      "3          0.0                   0.0        0.0  \n",
      "4          0.0                   0.0        0.0  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_841/561780463.py:1: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('loans_2007.csv')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('loans_2007.csv')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(1.5273666381835938)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thousand_row = pd.read_csv('loans_2007.csv', nrows=1000)\n",
    "thousand_row.memory_usage(deep=True).sum()/(1024*1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's try tripling to 3000 rows and calculate the memory footprint for each chunk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.580394744873047\n",
      "4.576141357421875\n",
      "4.577898979187012\n",
      "4.579251289367676\n",
      "4.575444221496582\n",
      "4.577326774597168\n",
      "4.575918197631836\n",
      "4.578287124633789\n",
      "4.576413154602051\n",
      "4.57646369934082\n",
      "4.589176177978516\n",
      "4.588043212890625\n",
      "4.594850540161133\n",
      "4.828314781188965\n",
      "0.868586540222168\n"
     ]
    }
   ],
   "source": [
    "chunk_iter = pd.read_csv('loans_2007.csv', chunksize=3000)\n",
    "for chunk in chunk_iter:\n",
    "    print(chunk.memory_usage(deep=True).sum()/(1024*1024))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### how many rows in the dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42538\n"
     ]
    }
   ],
   "source": [
    "chunk_iter = pd.read_csv('loans_2007.csv', chunksize=3000)\n",
    "total_rows = 0\n",
    "for chunk in chunk_iter:\n",
    "    total_rows += len(chunk)\n",
    "print(total_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the Data in Chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many columns have a numeric type? How many have a string type?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 30, 30]\n",
      "[21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 22, 22]\n"
     ]
    }
   ],
   "source": [
    "chunk_iter = pd.read_csv('loans_2007.csv', chunksize=3000)\n",
    "num_cols = []\n",
    "str_cols = []\n",
    "for chunk in chunk_iter:\n",
    "    num = chunk.select_dtypes(include=[np.number]).shape[1]\n",
    "    num_cols.append(num)\n",
    "    string = chunk.select_dtypes(include=['object']).shape[1]\n",
    "    str_cols.append(string)\n",
    "print(num_cols)\n",
    "print(str_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall string cols are: ['term', 'int_rate', 'grade', 'sub_grade', 'emp_title', 'emp_length', 'home_ownership', 'verification_status', 'issue_d', 'loan_status', 'pymnt_plan', 'purpose', 'title', 'zip_code', 'addr_state', 'earliest_cr_line', 'revol_util', 'initial_list_status', 'last_pymnt_d', 'last_credit_pull_d', 'application_type']\n",
      "chunk string cols are: ['id', 'term', 'int_rate', 'grade', 'sub_grade', 'emp_title', 'emp_length', 'home_ownership', 'verification_status', 'issue_d', 'loan_status', 'pymnt_plan', 'purpose', 'title', 'zip_code', 'addr_state', 'earliest_cr_line', 'revol_util', 'initial_list_status', 'last_pymnt_d', 'last_credit_pull_d', 'application_type']\n",
      "overall string cols are: ['term', 'int_rate', 'grade', 'sub_grade', 'emp_title', 'emp_length', 'home_ownership', 'verification_status', 'issue_d', 'loan_status', 'pymnt_plan', 'purpose', 'title', 'zip_code', 'addr_state', 'earliest_cr_line', 'revol_util', 'initial_list_status', 'last_pymnt_d', 'last_credit_pull_d', 'application_type']\n",
      "chunk string cols are: ['id', 'term', 'int_rate', 'grade', 'sub_grade', 'emp_title', 'emp_length', 'home_ownership', 'verification_status', 'issue_d', 'loan_status', 'pymnt_plan', 'purpose', 'title', 'zip_code', 'addr_state', 'earliest_cr_line', 'revol_util', 'initial_list_status', 'last_pymnt_d', 'last_credit_pull_d', 'application_type']\n"
     ]
    }
   ],
   "source": [
    "# check if string cols are consistent in each chunk\n",
    "chunk_iter = pd.read_csv('loans_2007.csv', chunksize=3000)\n",
    "obj_col = []\n",
    "for chunk in chunk_iter:\n",
    "    chunk_obj_col = chunk.select_dtypes(include=['object']).columns.to_list()\n",
    "    if len(obj_col) > 0:\n",
    "        is_same = chunk_obj_col == obj_col\n",
    "        if not is_same:\n",
    "            print('overall string cols are:', obj_col)\n",
    "            print('chunk string cols are:', chunk_obj_col)\n",
    "            \n",
    "    else:\n",
    "        obj_col = chunk_obj_col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation 1: By default — 31 numeric columns and 21 string columns.\n",
    "\n",
    "Observation 2: It seems like one column in particular (the id column) is being cast to int64 in the last 2 chunks but not in the earlier chunks. Since the id column won't be useful for analysis, visualization, or predictive modeling, let's ignore this column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many unique values are there in each string column? How many of the string columns contain values that are less than 50% unique?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'term': 2, 'int_rate': 394, 'grade': 7, 'sub_grade': 35, 'emp_title': 30658, 'emp_length': 11, 'home_ownership': 5, 'verification_status': 3, 'issue_d': 55, 'loan_status': 9, 'pymnt_plan': 2, 'purpose': 14, 'title': 21264, 'zip_code': 837, 'addr_state': 50, 'earliest_cr_line': 530, 'revol_util': 1119, 'initial_list_status': 1, 'last_pymnt_d': 103, 'last_credit_pull_d': 108, 'application_type': 1, 'id': 3538}\n",
      "21\n"
     ]
    }
   ],
   "source": [
    "chunk_iter = pd.read_csv('loans_2007.csv', chunksize=3000)\n",
    "unique = {}\n",
    "total_rows = 0\n",
    "for chunk in chunk_iter:\n",
    "    se_cols = chunk.select_dtypes(include=['object'])\n",
    "    fin_cols = se_cols.columns\n",
    "    total_rows += len(chunk)\n",
    "    for col in fin_cols:\n",
    "        val_count = se_cols[col].value_counts()\n",
    "        if col in unique:\n",
    "            unique[col].append(val_count)\n",
    "        else:\n",
    "            unique[col] = [val_count]\n",
    "            \n",
    "col_les_50_perc = 0 \n",
    "col_uni_val = {}\n",
    "for c in unique:\n",
    "    concat_col = pd.concat(unique[c])\n",
    "    group_count = concat_col.groupby(concat_col.index).sum()\n",
    "    col_uni_val[c] = len(group_count)\n",
    "    uni_perc = len(group_count)/total_rows\n",
    "    if uni_perc < 0.5:\n",
    "        col_les_50_perc += 1    \n",
    "print(col_uni_val)\n",
    "print(col_les_50_perc)\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'term': 2, 'int_rate': 394, 'grade': 7, 'sub_grade': 35, 'emp_title': 30658, 'emp_length': 11, 'home_ownership': 5, 'verification_status': 3, 'issue_d': 55, 'loan_status': 9, 'pymnt_plan': 2, 'purpose': 14, 'title': 21264, 'zip_code': 837, 'addr_state': 50, 'earliest_cr_line': 530, 'revol_util': 1119, 'initial_list_status': 1, 'last_pymnt_d': 103, 'last_credit_pull_d': 108, 'application_type': 1, 'id': 3538}\n",
      "42538\n",
      "21\n"
     ]
    }
   ],
   "source": [
    "# another way to use set instead of dictionary to do unique values counts\n",
    "\n",
    "chunk_iter = pd.read_csv('loans_2007.csv', chunksize=3000)\n",
    "uniques_per_col = {}\n",
    "total_rows = 0\n",
    "for chunk in chunk_iter:\n",
    "    se_cols = chunk.select_dtypes(include=['object'])\n",
    "    col_names = se_cols.columns\n",
    "    total_rows += len(chunk)\n",
    "    \n",
    "    for col in col_names:\n",
    "        \n",
    "        val_count = se_cols[col].value_counts()\n",
    "        if col in uniques_per_col:\n",
    "            uniques_per_col[col].update(val_count.index)\n",
    "        else:\n",
    "            uniques_per_col[col] = set(val_count.index)\n",
    "            \n",
    "# create a dictionary for the amount of unique values of each column             \n",
    "num_uni_col = {}\n",
    "for key in uniques_per_col.keys():\n",
    "    num_uni_col[key] = len(uniques_per_col[key])\n",
    "print(num_uni_col)\n",
    "\n",
    "num_cols_less_50_perc = 0\n",
    "for val in num_uni_col.values():\n",
    "    if val/total_rows < 0.5:\n",
    "        num_cols_less_50_perc += 1\n",
    "    \n",
    "print(total_rows)\n",
    "print(num_cols_less_50_perc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_841/1169366068.py:1: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('loans_2007.csv')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('loans_2007.csv')\n",
    "ob_cols = df.select_dtypes(include=['object'])\n",
    "print(len(ob_cols.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 42538, 'term': 2, 'int_rate': 394, 'grade': 7, 'sub_grade': 35, 'emp_title': 30658, 'emp_length': 11, 'home_ownership': 5, 'verification_status': 3, 'issue_d': 55, 'loan_status': 9, 'pymnt_plan': 2, 'purpose': 14, 'title': 21264, 'zip_code': 837, 'addr_state': 50, 'earliest_cr_line': 530, 'revol_util': 1119, 'initial_list_status': 1, 'last_pymnt_d': 103, 'last_credit_pull_d': 108, 'application_type': 1}\n"
     ]
    }
   ],
   "source": [
    "col_uni = {}\n",
    "for col in ob_cols.columns:\n",
    "    col_uni[col] = ob_cols[col].nunique()\n",
    "print(col_uni)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which float columns have no missing values and could be candidates for conversion to the integer type?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collection_recovery_fee          3\n",
      "dti                              3\n",
      "loan_amnt                        3\n",
      "member_id                        3\n",
      "last_pymnt_amnt                  3\n",
      "installment                      3\n",
      "funded_amnt_inv                  3\n",
      "funded_amnt                      3\n",
      "total_pymnt                      3\n",
      "total_pymnt_inv                  3\n",
      "total_rec_int                    3\n",
      "revol_bal                        3\n",
      "recoveries                       3\n",
      "policy_code                      3\n",
      "out_prncp_inv                    3\n",
      "out_prncp                        3\n",
      "total_rec_prncp                  3\n",
      "total_rec_late_fee               3\n",
      "annual_inc                       7\n",
      "open_acc                        32\n",
      "delinq_amnt                     32\n",
      "delinq_2yrs                     32\n",
      "acc_now_delinq                  32\n",
      "inq_last_6mths                  32\n",
      "pub_rec                         32\n",
      "total_acc                       32\n",
      "tax_liens                      108\n",
      "collections_12_mths_ex_med     148\n",
      "chargeoff_within_12_mths       148\n",
      "pub_rec_bankruptcies          1368\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "chunk_iter = pd.read_csv('loans_2007.csv', chunksize=3000)\n",
    "missing = []\n",
    "for chunk in chunk_iter:\n",
    "    floats_col_df = chunk.select_dtypes(include=['float'])\n",
    "    missing.append(floats_col_df.apply(pd.isnull).sum())\n",
    "    \n",
    "combined_missing = pd.concat(missing)\n",
    "col_mis_val_amount = combined_missing.groupby(combined_missing.index).sum().sort_values()\n",
    "print(col_mis_val_amount)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the total memory usage across all of the chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65.24251079559326\n"
     ]
    }
   ],
   "source": [
    "chunk_iter = pd.read_csv('loans_2007.csv', chunksize=3000)\n",
    "total_mem_use = []\n",
    "for chunk in chunk_iter:\n",
    "    total_mem_use.append(chunk.memory_usage(deep=True).sum()/(1024*1024))\n",
    "print(sum(total_mem_use))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65.24251079559326\n"
     ]
    }
   ],
   "source": [
    "chunk_iter = pd.read_csv('loans_2007.csv', chunksize=3000)\n",
    "total_mem_use = 0\n",
    "for chunk in chunk_iter:\n",
    "    total_mem_use += chunk.memory_usage(deep=True).sum()/(1024*1024)\n",
    "print(total_mem_use)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizing String Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine which string columns you can convert to a numeric type if you clean them. Let's focus on columns that would actually be useful for analysis and modeling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['term',\n",
       " 'int_rate',\n",
       " 'grade',\n",
       " 'sub_grade',\n",
       " 'emp_title',\n",
       " 'emp_length',\n",
       " 'home_ownership',\n",
       " 'verification_status',\n",
       " 'issue_d',\n",
       " 'loan_status',\n",
       " 'pymnt_plan',\n",
       " 'purpose',\n",
       " 'title',\n",
       " 'zip_code',\n",
       " 'addr_state',\n",
       " 'earliest_cr_line',\n",
       " 'revol_util',\n",
       " 'initial_list_status',\n",
       " 'last_pymnt_d',\n",
       " 'last_credit_pull_d',\n",
       " 'application_type']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj_col \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_ob_cols = ['term', 'sub_grade', 'emp_title', 'home_ownership', 'verification_status', 'issue_d', 'purpose', 'earliest_cr_line', 'revol_util', 'last_pymnt_d', 'last_credit_pull_d']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['term', 'int_rate', 'grade', 'sub_grade', 'emp_title', 'emp_length', 'home_ownership', 'verification_status', 'issue_d', 'loan_status', 'pymnt_plan', 'purpose', 'title', 'zip_code', 'addr_state', 'earliest_cr_line', 'revol_util', 'initial_list_status', 'last_pymnt_d', 'last_credit_pull_d', 'application_type', 'id'])\n"
     ]
    }
   ],
   "source": [
    "chunk_loan = pd.read_csv('loans_2007.csv', chunksize=3000)\n",
    "loan_unique_val_counts = {}\n",
    "for chunk in chunk_loan:\n",
    "    str_cols = chunk.select_dtypes(include=['object'])\n",
    "    for col in str_cols.columns:\n",
    "        val_count = str_cols[col].value_counts()\n",
    "        if col in loan_unique_val_counts:\n",
    "            loan_unique_val_counts[col].append(val_count)\n",
    "        else:\n",
    "            loan_unique_val_counts[col] = [val_count]\n",
    "            \n",
    "combined_unique_count = {}\n",
    "for col in loan_unique_val_counts:\n",
    "    combined_col = pd.concat(loan_unique_val_counts[col])\n",
    "    final_val_counts = combined_col.groupby(combined_col.index).sum()\n",
    "    combined_unique_count[col] = final_val_counts\n",
    "#print(combined_unique_count)\n",
    "print(combined_unique_count.keys())   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "term\n",
      "term\n",
      "36 months    31534\n",
      "60 months    11001\n",
      "Name: count, dtype: int64\n",
      "-----------\n",
      "sub_grade\n",
      "sub_grade\n",
      "A1    1142\n",
      "A2    1520\n",
      "A3    1823\n",
      "A4    2905\n",
      "A5    2793\n",
      "B1    1882\n",
      "B2    2113\n",
      "B3    2997\n",
      "B4    2590\n",
      "B5    2807\n",
      "C1    2264\n",
      "C2    2157\n",
      "C3    1658\n",
      "C4    1370\n",
      "C5    1291\n",
      "D1    1053\n",
      "D2    1485\n",
      "D3    1322\n",
      "D4    1140\n",
      "D5    1016\n",
      "E1     884\n",
      "E2     791\n",
      "E3     668\n",
      "E4     552\n",
      "E5     499\n",
      "F1     392\n",
      "F2     308\n",
      "F3     236\n",
      "F4     211\n",
      "F5     154\n",
      "G1     141\n",
      "G2     107\n",
      "G3      79\n",
      "G4      99\n",
      "G5      86\n",
      "Name: count, dtype: int64\n",
      "-----------\n",
      "emp_title\n",
      "emp_title\n",
      "  old palm inc                       1\n",
      " Brocade Communications              1\n",
      " CenturyLink                         1\n",
      " Department of Homeland Security     1\n",
      " Down To Earth Distributors, Inc.    1\n",
      "                                    ..\n",
      "zashko inc.                          1\n",
      "zeno office solutions                1\n",
      "zion lutheran school                 1\n",
      "zoll medical corp                    1\n",
      "zozaya officiating                   1\n",
      "Name: count, Length: 30658, dtype: int64\n",
      "-----------\n",
      "home_ownership\n",
      "home_ownership\n",
      "MORTGAGE    18959\n",
      "NONE            8\n",
      "OTHER         136\n",
      "OWN          3251\n",
      "RENT        20181\n",
      "Name: count, dtype: int64\n",
      "-----------\n",
      "verification_status\n",
      "verification_status\n",
      "Not Verified       18758\n",
      "Source Verified    10306\n",
      "Verified           13471\n",
      "Name: count, dtype: int64\n",
      "-----------\n",
      "issue_d\n",
      "issue_d\n",
      "Apr-2008     259\n",
      "Apr-2009     333\n",
      "Apr-2010     912\n",
      "Apr-2011    1563\n",
      "Aug-2007      74\n",
      "Aug-2008     100\n",
      "Aug-2009     446\n",
      "Aug-2010    1175\n",
      "Aug-2011    1934\n",
      "Dec-2007     172\n",
      "Dec-2008     253\n",
      "Dec-2009     658\n",
      "Dec-2010    1335\n",
      "Dec-2011    2267\n",
      "Feb-2008     306\n",
      "Feb-2009     302\n",
      "Feb-2010     682\n",
      "Feb-2011    1298\n",
      "Jan-2008     305\n",
      "Jan-2009     269\n",
      "Jan-2010     662\n",
      "Jan-2011    1380\n",
      "Jul-2007      63\n",
      "Jul-2008     141\n",
      "Jul-2009     411\n",
      "Jul-2010    1204\n",
      "Jul-2011    1875\n",
      "Jun-2007      24\n",
      "Jun-2008     124\n",
      "Jun-2009     406\n",
      "Jun-2010    1105\n",
      "Jun-2011    1835\n",
      "Mar-2008     402\n",
      "Mar-2009     324\n",
      "Mar-2010     828\n",
      "Mar-2011    1448\n",
      "May-2008     115\n",
      "May-2009     359\n",
      "May-2010     989\n",
      "May-2011    1704\n",
      "Nov-2007     112\n",
      "Nov-2008     209\n",
      "Nov-2009     662\n",
      "Nov-2010    1224\n",
      "Nov-2011    2232\n",
      "Oct-2007     105\n",
      "Oct-2008     122\n",
      "Oct-2009     604\n",
      "Oct-2010    1232\n",
      "Oct-2011    2118\n",
      "Sep-2007      53\n",
      "Sep-2008      57\n",
      "Sep-2009     507\n",
      "Sep-2010    1189\n",
      "Sep-2011    2067\n",
      "Name: count, dtype: int64\n",
      "-----------\n",
      "purpose\n",
      "purpose\n",
      "car                    1615\n",
      "credit_card            5477\n",
      "debt_consolidation    19776\n",
      "educational             422\n",
      "home_improvement       3199\n",
      "house                   426\n",
      "major_purchase         2311\n",
      "medical                 753\n",
      "moving                  629\n",
      "other                  4425\n",
      "renewable_energy        106\n",
      "small_business         1992\n",
      "vacation                400\n",
      "wedding                1004\n",
      "Name: count, dtype: int64\n",
      "-----------\n",
      "earliest_cr_line\n",
      "earliest_cr_line\n",
      "Apr-1964      3\n",
      "Apr-1966      1\n",
      "Apr-1967      4\n",
      "Apr-1968      1\n",
      "Apr-1969      1\n",
      "           ... \n",
      "Sep-2004    221\n",
      "Sep-2005    162\n",
      "Sep-2006    150\n",
      "Sep-2007     63\n",
      "Sep-2008      8\n",
      "Name: count, Length: 530, dtype: int64\n",
      "-----------\n",
      "revol_util\n",
      "revol_util\n",
      "0%       1070\n",
      "0.01%       1\n",
      "0.03%       1\n",
      "0.04%       1\n",
      "0.05%       1\n",
      "         ... \n",
      "99.5%      24\n",
      "99.6%      27\n",
      "99.7%      32\n",
      "99.8%      25\n",
      "99.9%      29\n",
      "Name: count, Length: 1119, dtype: int64\n",
      "-----------\n",
      "last_pymnt_d\n",
      "last_pymnt_d\n",
      "Apr-2008     23\n",
      "Apr-2009     72\n",
      "Apr-2010    145\n",
      "Apr-2011    519\n",
      "Apr-2012    781\n",
      "           ... \n",
      "Sep-2011    491\n",
      "Sep-2012    802\n",
      "Sep-2013    712\n",
      "Sep-2014    694\n",
      "Sep-2015    211\n",
      "Name: count, Length: 103, dtype: int64\n",
      "-----------\n",
      "last_credit_pull_d\n",
      "last_credit_pull_d\n",
      "Apr-2009     24\n",
      "Apr-2010     77\n",
      "Apr-2011    177\n",
      "Apr-2012    326\n",
      "Apr-2013    445\n",
      "           ... \n",
      "Sep-2011    175\n",
      "Sep-2012    414\n",
      "Sep-2013    408\n",
      "Sep-2014    564\n",
      "Sep-2015    531\n",
      "Name: count, Length: 108, dtype: int64\n",
      "-----------\n"
     ]
    }
   ],
   "source": [
    "for colu in use_ob_cols:\n",
    "    print(colu)\n",
    "    print(combined_unique_count[colu])\n",
    "    print(\"-----------\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chunk_loan = pd.read_csv('loans_2007.csv', chunksize=3000)\n",
    "# loan_unique_val_counts = {}\n",
    "# for chunk in chunk_loan:\n",
    "#     str_cols = chunk.select_dtypes(include=['object'])\n",
    "#     for col in str_cols.columns:\n",
    "#         val_count = str_cols[col].value_counts()\n",
    "#         if col in loan_unique_val_counts:\n",
    "#             loan_unique_val_counts[col].update(val_count.index)\n",
    "#         else:\n",
    "#             loan_unique_val_counts[col] = set(val_count.index)\n",
    "            \n",
    "# combined_unique_count = {}\n",
    "# for col in loan_unique_val_counts:\n",
    "#     combined_col = pd.concat(loan_unique_val_counts[col])\n",
    "#     final_val_counts = combined_col.groupby(combined_col.index).sum()\n",
    "#     combined_unique_count[col] = final_val_counts\n",
    "# print(combined_unique_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_col_dtype = {'sub_grade':'category', 'home_ownership':'category', 'verification_status':'category', 'purpose':'category'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert term and revol_util to numerical by data cleaning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert issue_d, earliest_cr_line, last_pymnt_d, and last_credit_pull_d to datetime.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>sub_grade</th>\n",
       "      <th>emp_title</th>\n",
       "      <th>home_ownership</th>\n",
       "      <th>verification_status</th>\n",
       "      <th>issue_d</th>\n",
       "      <th>purpose</th>\n",
       "      <th>earliest_cr_line</th>\n",
       "      <th>revol_util</th>\n",
       "      <th>last_pymnt_d</th>\n",
       "      <th>last_credit_pull_d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42000</th>\n",
       "      <td>36 months</td>\n",
       "      <td>C2</td>\n",
       "      <td>Best Buy</td>\n",
       "      <td>RENT</td>\n",
       "      <td>Not Verified</td>\n",
       "      <td>Feb-2008</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>Jul-2000</td>\n",
       "      <td>100.7%</td>\n",
       "      <td>Feb-2011</td>\n",
       "      <td>Jun-2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42001</th>\n",
       "      <td>36 months</td>\n",
       "      <td>G2</td>\n",
       "      <td>CVS PHARMACY</td>\n",
       "      <td>OWN</td>\n",
       "      <td>Not Verified</td>\n",
       "      <td>Feb-2008</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>Mar-1989</td>\n",
       "      <td>51.9%</td>\n",
       "      <td>Nov-2008</td>\n",
       "      <td>Jun-2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42002</th>\n",
       "      <td>36 months</td>\n",
       "      <td>E4</td>\n",
       "      <td>General Motors</td>\n",
       "      <td>RENT</td>\n",
       "      <td>Not Verified</td>\n",
       "      <td>Feb-2008</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>Dec-1998</td>\n",
       "      <td>80.7%</td>\n",
       "      <td>Feb-2011</td>\n",
       "      <td>Jun-2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42003</th>\n",
       "      <td>36 months</td>\n",
       "      <td>G4</td>\n",
       "      <td>usa medical center</td>\n",
       "      <td>RENT</td>\n",
       "      <td>Not Verified</td>\n",
       "      <td>Feb-2008</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>Jul-1995</td>\n",
       "      <td>57.2%</td>\n",
       "      <td>Feb-2011</td>\n",
       "      <td>Jun-2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42004</th>\n",
       "      <td>36 months</td>\n",
       "      <td>B3</td>\n",
       "      <td>InvestSource Inc</td>\n",
       "      <td>RENT</td>\n",
       "      <td>Not Verified</td>\n",
       "      <td>Feb-2008</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>Sep-2005</td>\n",
       "      <td>74%</td>\n",
       "      <td>Mar-2010</td>\n",
       "      <td>Aug-2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42533</th>\n",
       "      <td>36 months</td>\n",
       "      <td>B3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RENT</td>\n",
       "      <td>Not Verified</td>\n",
       "      <td>Jun-2007</td>\n",
       "      <td>other</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jun-2010</td>\n",
       "      <td>May-2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42534</th>\n",
       "      <td>36 months</td>\n",
       "      <td>A5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NONE</td>\n",
       "      <td>Not Verified</td>\n",
       "      <td>Jun-2007</td>\n",
       "      <td>other</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jun-2010</td>\n",
       "      <td>Aug-2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42535</th>\n",
       "      <td>36 months</td>\n",
       "      <td>A3</td>\n",
       "      <td>Homemaker</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>Not Verified</td>\n",
       "      <td>Jun-2007</td>\n",
       "      <td>other</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jun-2010</td>\n",
       "      <td>Feb-2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42536</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42537</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>538 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             term sub_grade           emp_title home_ownership  \\\n",
       "42000   36 months        C2            Best Buy           RENT   \n",
       "42001   36 months        G2        CVS PHARMACY            OWN   \n",
       "42002   36 months        E4      General Motors           RENT   \n",
       "42003   36 months        G4  usa medical center           RENT   \n",
       "42004   36 months        B3    InvestSource Inc           RENT   \n",
       "...           ...       ...                 ...            ...   \n",
       "42533   36 months        B3                 NaN           RENT   \n",
       "42534   36 months        A5                 NaN           NONE   \n",
       "42535   36 months        A3           Homemaker       MORTGAGE   \n",
       "42536         NaN       NaN                 NaN            NaN   \n",
       "42537         NaN       NaN                 NaN            NaN   \n",
       "\n",
       "      verification_status   issue_d             purpose earliest_cr_line  \\\n",
       "42000        Not Verified  Feb-2008  debt_consolidation         Jul-2000   \n",
       "42001        Not Verified  Feb-2008  debt_consolidation         Mar-1989   \n",
       "42002        Not Verified  Feb-2008  debt_consolidation         Dec-1998   \n",
       "42003        Not Verified  Feb-2008  debt_consolidation         Jul-1995   \n",
       "42004        Not Verified  Feb-2008  debt_consolidation         Sep-2005   \n",
       "...                   ...       ...                 ...              ...   \n",
       "42533        Not Verified  Jun-2007               other              NaN   \n",
       "42534        Not Verified  Jun-2007               other              NaN   \n",
       "42535        Not Verified  Jun-2007               other              NaN   \n",
       "42536                 NaN       NaN                 NaN              NaN   \n",
       "42537                 NaN       NaN                 NaN              NaN   \n",
       "\n",
       "      revol_util last_pymnt_d last_credit_pull_d  \n",
       "42000     100.7%     Feb-2011           Jun-2016  \n",
       "42001      51.9%     Nov-2008           Jun-2016  \n",
       "42002      80.7%     Feb-2011           Jun-2016  \n",
       "42003      57.2%     Feb-2011           Jun-2011  \n",
       "42004        74%     Mar-2010           Aug-2010  \n",
       "...          ...          ...                ...  \n",
       "42533        NaN     Jun-2010           May-2007  \n",
       "42534        NaN     Jun-2010           Aug-2007  \n",
       "42535        NaN     Jun-2010           Feb-2015  \n",
       "42536        NaN          NaN                NaN  \n",
       "42537        NaN          NaN                NaN  \n",
       "\n",
       "[538 rows x 11 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk[use_ob_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  Calculate missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_841/1026666455.py:4: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  for chunk in chunk_iter:\n",
      "/tmp/ipykernel_841/1026666455.py:4: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  for chunk in chunk_iter:\n",
      "/tmp/ipykernel_841/1026666455.py:4: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  for chunk in chunk_iter:\n",
      "/tmp/ipykernel_841/1026666455.py:4: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  for chunk in chunk_iter:\n",
      "/tmp/ipykernel_841/1026666455.py:4: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  for chunk in chunk_iter:\n",
      "/tmp/ipykernel_841/1026666455.py:4: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  for chunk in chunk_iter:\n",
      "/tmp/ipykernel_841/1026666455.py:4: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  for chunk in chunk_iter:\n",
      "/tmp/ipykernel_841/1026666455.py:4: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  for chunk in chunk_iter:\n",
      "/tmp/ipykernel_841/1026666455.py:4: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  for chunk in chunk_iter:\n",
      "/tmp/ipykernel_841/1026666455.py:4: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  for chunk in chunk_iter:\n",
      "/tmp/ipykernel_841/1026666455.py:4: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  for chunk in chunk_iter:\n",
      "/tmp/ipykernel_841/1026666455.py:4: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  for chunk in chunk_iter:\n",
      "/tmp/ipykernel_841/1026666455.py:4: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  for chunk in chunk_iter:\n",
      "/tmp/ipykernel_841/1026666455.py:4: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  for chunk in chunk_iter:\n",
      "/tmp/ipykernel_841/1026666455.py:4: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  for chunk in chunk_iter:\n",
      "/tmp/ipykernel_841/1026666455.py:4: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  for chunk in chunk_iter:\n",
      "/tmp/ipykernel_841/1026666455.py:4: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  for chunk in chunk_iter:\n",
      "/tmp/ipykernel_841/1026666455.py:4: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  for chunk in chunk_iter:\n",
      "/tmp/ipykernel_841/1026666455.py:4: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  for chunk in chunk_iter:\n",
      "/tmp/ipykernel_841/1026666455.py:4: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  for chunk in chunk_iter:\n",
      "/tmp/ipykernel_841/1026666455.py:4: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  for chunk in chunk_iter:\n",
      "/tmp/ipykernel_841/1026666455.py:4: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  for chunk in chunk_iter:\n",
      "/tmp/ipykernel_841/1026666455.py:4: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  for chunk in chunk_iter:\n",
      "/tmp/ipykernel_841/1026666455.py:4: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  for chunk in chunk_iter:\n",
      "/tmp/ipykernel_841/1026666455.py:4: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  for chunk in chunk_iter:\n",
      "/tmp/ipykernel_841/1026666455.py:4: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  for chunk in chunk_iter:\n",
      "/tmp/ipykernel_841/1026666455.py:4: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  for chunk in chunk_iter:\n",
      "/tmp/ipykernel_841/1026666455.py:4: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  for chunk in chunk_iter:\n",
      "/tmp/ipykernel_841/1026666455.py:4: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  for chunk in chunk_iter:\n",
      "/tmp/ipykernel_841/1026666455.py:4: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  for chunk in chunk_iter:\n",
      "/tmp/ipykernel_841/1026666455.py:4: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  for chunk in chunk_iter:\n",
      "/tmp/ipykernel_841/1026666455.py:4: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  for chunk in chunk_iter:\n",
      "/tmp/ipykernel_841/1026666455.py:4: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  for chunk in chunk_iter:\n",
      "/tmp/ipykernel_841/1026666455.py:4: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  for chunk in chunk_iter:\n",
      "/tmp/ipykernel_841/1026666455.py:4: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  for chunk in chunk_iter:\n",
      "/tmp/ipykernel_841/1026666455.py:4: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  for chunk in chunk_iter:\n",
      "/tmp/ipykernel_841/1026666455.py:4: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  for chunk in chunk_iter:\n",
      "/tmp/ipykernel_841/1026666455.py:4: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  for chunk in chunk_iter:\n",
      "/tmp/ipykernel_841/1026666455.py:4: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  for chunk in chunk_iter:\n",
      "/tmp/ipykernel_841/1026666455.py:4: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  for chunk in chunk_iter:\n",
      "/tmp/ipykernel_841/1026666455.py:4: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  for chunk in chunk_iter:\n",
      "/tmp/ipykernel_841/1026666455.py:4: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  for chunk in chunk_iter:\n",
      "/tmp/ipykernel_841/1026666455.py:4: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  for chunk in chunk_iter:\n",
      "/tmp/ipykernel_841/1026666455.py:4: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  for chunk in chunk_iter:\n",
      "/tmp/ipykernel_841/1026666455.py:4: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  for chunk in chunk_iter:\n",
      "/tmp/ipykernel_841/1026666455.py:4: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  for chunk in chunk_iter:\n",
      "/tmp/ipykernel_841/1026666455.py:4: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  for chunk in chunk_iter:\n",
      "/tmp/ipykernel_841/1026666455.py:4: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  for chunk in chunk_iter:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'member_id': 3, 'loan_amnt': 3, 'funded_amnt': 3, 'funded_amnt_inv': 3, 'installment': 3, 'annual_inc': 7, 'dti': 3, 'delinq_2yrs': 32, 'inq_last_6mths': 32, 'open_acc': 32, 'pub_rec': 32, 'revol_bal': 3, 'revol_util': 93, 'total_acc': 32, 'out_prncp': 3, 'out_prncp_inv': 3, 'total_pymnt': 3, 'total_pymnt_inv': 3, 'total_rec_prncp': 3, 'total_rec_int': 3, 'total_rec_late_fee': 3, 'recoveries': 3, 'collection_recovery_fee': 3, 'last_pymnt_amnt': 3, 'collections_12_mths_ex_med': 148, 'policy_code': 3, 'acc_now_delinq': 32, 'chargeoff_within_12_mths': 148, 'delinq_amnt': 32, 'pub_rec_bankruptcies': 1368, 'tax_liens': 108, 'term': 3}\n",
      "41.08497142791748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_841/1026666455.py:4: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  for chunk in chunk_iter:\n",
      "/tmp/ipykernel_841/1026666455.py:4: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  for chunk in chunk_iter:\n",
      "/tmp/ipykernel_841/1026666455.py:4: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  for chunk in chunk_iter:\n",
      "/tmp/ipykernel_841/1026666455.py:4: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  for chunk in chunk_iter:\n",
      "/tmp/ipykernel_841/1026666455.py:4: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  for chunk in chunk_iter:\n",
      "/tmp/ipykernel_841/1026666455.py:4: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  for chunk in chunk_iter:\n",
      "/tmp/ipykernel_841/1026666455.py:4: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  for chunk in chunk_iter:\n",
      "/tmp/ipykernel_841/1026666455.py:4: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  for chunk in chunk_iter:\n",
      "/tmp/ipykernel_841/1026666455.py:4: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  for chunk in chunk_iter:\n",
      "/tmp/ipykernel_841/1026666455.py:4: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  for chunk in chunk_iter:\n",
      "/tmp/ipykernel_841/1026666455.py:4: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  for chunk in chunk_iter:\n",
      "/tmp/ipykernel_841/1026666455.py:4: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  for chunk in chunk_iter:\n"
     ]
    }
   ],
   "source": [
    "chunk_iter = pd.read_csv('loans_2007.csv', chunksize=3000, dtype=convert_col_dtype, parse_dates=['issue_d', 'earliest_cr_line', 'last_pymnt_d', 'last_credit_pull_d'])\n",
    "float_cols_count = {}\n",
    "mem_use = 0\n",
    "for chunk in chunk_iter:\n",
    "        term_clean = chunk['term'].apply(lambda x: str(x).lstrip(' ').rstrip(' months') if not pd.isna(x) else x)\n",
    "        revol_clean = chunk['revol_util'].apply(lambda x: str(x).rstrip('%') if not pd.isna(x) else x)\n",
    "        chunk['term'] = pd.to_numeric(term_clean)\n",
    "        chunk['revol_util'] = pd.to_numeric(revol_clean)\n",
    "        float_cols = chunk.select_dtypes(include=['float'])\n",
    "        mem_use  += chunk.memory_usage(deep=True).sum()/(1024**2\n",
    "                                                          )\n",
    "        for col in float_cols.columns:\n",
    "            missing_values = int(len(chunk) - float_cols[col].count())\n",
    "            if col in float_cols_count:\n",
    "                float_cols_count[col] += missing_values\n",
    "            else:\n",
    "                float_cols_count[col] = missing_values\n",
    "                \n",
    "print(float_cols_count)\n",
    "print(mem_use)\n",
    "\n",
    "# another way to process the data \n",
    "#     term_cleaned = chunk['term'].str.lstrip(\" \").str.rstrip(\" months\")\n",
    "#     revol_cleaned = chunk['revol_util'].str.rstrip(\"%\")\n",
    "#     chunk['term'] = pd.to_numeric(term_cleaned)\n",
    "#     chunk['revol_util'] = pd.to_numeric(revol_cleaned)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
